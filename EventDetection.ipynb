{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use <b> chi squared score </b> to measure the trend in the twitter. \n",
    "The formula , use E for Expectation, and O for observation<br>\n",
    "$$\n",
    "\\chi^2 \\text{score}= \\left\\{\\begin{array}{lr}\n",
    "        \\frac{(O-E)^2}{E}, & \\text{if } O > E\\\\\n",
    "        0, & \\text{otherwise }\n",
    "        \\end{array}\n",
    "        \\right.\n",
    "$$\n",
    "\n",
    "Zero division error will araise if E = 0, so we subsititude E with 1 in this case. <br>\n",
    "\n",
    "As some low frequency terms may have very large chi squared score, a threshold of 15 is used to\n",
    "filter these hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import collections\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"data/twitter-swisscom/twitter/df1_reduced.pickle\", \"rb\") as f:\n",
    "    df1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/twitter-swisscom/twitter/df2_reduced.pickle\", \"rb\") as f:\n",
    "    df2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/twitter-swisscom/twitter/df3_reduced.pickle\", \"rb\") as f:\n",
    "    df3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"data/twitter-swisscom/twitter/df4_reduced.pickle\", \"rb\") as f:\n",
    "    df4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/twitter-swisscom/user/user_total.pickle\", \"rb\") as f:\n",
    "    user = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4['day'] = df4['createdAt'].apply(lambda x: x[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base and Tags\n",
    "\n",
    "Use df1, df2, df3 (date before 2015) as base, the df4 is investigate to detect changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_hash_tags(series):\n",
    "    \"\"\" Count the number of hashtags (in lower cases)\"\"\"\n",
    "    d = collections.defaultdict(int)\n",
    "    \n",
    "    def count_a_list(l):\n",
    "        for i in l:\n",
    "            d[i.lower()] += 1\n",
    "            \n",
    "    series.apply(count_a_list)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1 = count_hash_tags(df1['hashtags'])\n",
    "d2 = count_hash_tags(df2['hashtags'])\n",
    "d3 = count_hash_tags(df3['hashtags'])\n",
    "d4 = count_hash_tags(df4['hashtags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_base_twitters = df1.shape[0] + df2.shape[0] + df3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_dict = collections.defaultdict(int, {k: d1[k] + d2[k] + d3[k] for k in set(d1) | set(d2)| set(d3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_dict_values(d, reverse=False):\n",
    "    \"\"\"sort dictionary by their values\"\"\"\n",
    "    return sorted(d.items(), key=lambda x: x[1], reverse=reverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Topic in Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topic_detection_by_chi_square(past, future, N, future_length, n=20):\n",
    "    \"\"\" Detect topics/events using chi squared score\n",
    "    \n",
    "    First compute the expected number from population `past`. If the expected\n",
    "    value is 0, we use 1 instead. If the expected number of a topic is smaller than\n",
    "    the one we observed (future), a potential event appears. Then we compute the \n",
    "    chi squared scores and sort them in the descending order.\n",
    "    \"\"\"\n",
    "    all_keys = set(future.keys()) | set(past.keys())\n",
    "    chi_squared_score = collections.defaultdict(float)\n",
    "\n",
    "    for k,v in future.items():\n",
    "        if N == 0:\n",
    "            expected = past[k] * future_length or 1\n",
    "        else:        \n",
    "            expected = past[k] / N * future_length or 1\n",
    "            \n",
    "        if v > expected and v > n:\n",
    "            # -0.5 is the Yates' correction to filter the low frequencies terms.\n",
    "            chi_squared_score[k] = (np.abs(expected - v)-0.5) ** 2 / expected\n",
    "        \n",
    "    return sort_dict_values(chi_squared_score, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overal Topic Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_N = num_base_twitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_base_dict = base_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def overal_topic(date_df, total_base_dict, total_N, n=20):\n",
    "    \"\"\"compute all the chi squared score from base datasets to a day's dataset\"\"\"\n",
    "    num_twitters_in_a_day = date_df.shape[0]\n",
    "    future = count_hash_tags(date_df.hashtags)\n",
    "    \n",
    "    chi_squared_dict = topic_detection_by_chi_square(total_base_dict, future, total_N, num_twitters_in_a_day, n)\n",
    "    \n",
    "    for k,v in future.items():\n",
    "        total_base_dict[k] += v\n",
    "\n",
    "    return chi_squared_dict[:5], total_N + num_twitters_in_a_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "days = df4.day.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bd7e0557d3ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moveral_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_base_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_N\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lie/.local/lib/python3.5/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[0;32m/home/lie/.local/lib/python3.5/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lie/.local/lib/python3.5/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "v = []\n",
    "for i, day in zip(range(10000), days):\n",
    "    df = df4[df4.day == day]\n",
    "    a = [day]\n",
    "    result, total_N = overal_topic(df, total_base_dict, total_N)\n",
    "    a.extend(result)\n",
    "    v.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overall_topics = pd.DataFrame(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>(davidebraccialetti, 123261065.614)</td>\n",
       "      <td>(braccialettirossi, 1090408.47591)</td>\n",
       "      <td>(switzerlandneedsotrat, 3840.32787285)</td>\n",
       "      <td>(atamadafelsefeyiunutma, 1332.25)</td>\n",
       "      <td>(switzerland, 14.3109812746)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>(switzerlandneedsotratour, 33731885.168)</td>\n",
       "      <td>(wewantotrainitaly2015, 59691.9480146)</td>\n",
       "      <td>(yeniturkiyei̇nsasindafelsefe, 5852.25)</td>\n",
       "      <td>(switzerlandneedsotrat, 1447.49075187)</td>\n",
       "      <td>(nashschristmasskit, 1447.30046921)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-30</td>\n",
       "      <td>(switzerlandneeds1dotrat, 4787810.32671)</td>\n",
       "      <td>(20thingsiwantfor2015, 1301800.37258)</td>\n",
       "      <td>(switzerlandneedsotratour, 469414.364522)</td>\n",
       "      <td>(neolieberswag, 17131.6748847)</td>\n",
       "      <td>(hollywoodmusicawards, 12773.2957978)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>(weneedotrainitaly2015, 825372.25)</td>\n",
       "      <td>(openrafahborder, 805625.184103)</td>\n",
       "      <td>(2015, 103923.947519)</td>\n",
       "      <td>(happynewyear, 35881.7318057)</td>\n",
       "      <td>(20thingsiwantfor2015, 29640.7442074)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>(ilovesuperjunior, 924482.25)</td>\n",
       "      <td>(ilovebts, 170625.650474)</td>\n",
       "      <td>(dmmedagi, 117581.106526)</td>\n",
       "      <td>(2015, 77109.7463785)</td>\n",
       "      <td>(happynewyear, 14038.5748095)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                         1  \\\n",
       "0  2014-12-28       (davidebraccialetti, 123261065.614)   \n",
       "1  2014-12-29  (switzerlandneedsotratour, 33731885.168)   \n",
       "2  2014-12-30  (switzerlandneeds1dotrat, 4787810.32671)   \n",
       "3  2014-12-31        (weneedotrainitaly2015, 825372.25)   \n",
       "4  2015-01-01             (ilovesuperjunior, 924482.25)   \n",
       "\n",
       "                                        2  \\\n",
       "0      (braccialettirossi, 1090408.47591)   \n",
       "1  (wewantotrainitaly2015, 59691.9480146)   \n",
       "2   (20thingsiwantfor2015, 1301800.37258)   \n",
       "3        (openrafahborder, 805625.184103)   \n",
       "4               (ilovebts, 170625.650474)   \n",
       "\n",
       "                                           3  \\\n",
       "0     (switzerlandneedsotrat, 3840.32787285)   \n",
       "1    (yeniturkiyei̇nsasindafelsefe, 5852.25)   \n",
       "2  (switzerlandneedsotratour, 469414.364522)   \n",
       "3                      (2015, 103923.947519)   \n",
       "4                  (dmmedagi, 117581.106526)   \n",
       "\n",
       "                                        4  \\\n",
       "0       (atamadafelsefeyiunutma, 1332.25)   \n",
       "1  (switzerlandneedsotrat, 1447.49075187)   \n",
       "2          (neolieberswag, 17131.6748847)   \n",
       "3           (happynewyear, 35881.7318057)   \n",
       "4                   (2015, 77109.7463785)   \n",
       "\n",
       "                                       5  \n",
       "0           (switzerland, 14.3109812746)  \n",
       "1    (nashschristmasskit, 1447.30046921)  \n",
       "2  (hollywoodmusicawards, 12773.2957978)  \n",
       "3  (20thingsiwantfor2015, 29640.7442074)  \n",
       "4          (happynewyear, 14038.5748095)  "
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overall_topics.to_csv(\"web/Analysis/overall_topics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-12-28\n",
      "2014-12-29\n",
      "2014-12-30\n",
      "2014-12-31\n",
      "2015-01-01\n",
      "2015-01-02\n",
      "2015-01-03\n",
      "2015-01-04\n",
      "2015-01-05\n",
      "2015-01-06\n",
      "2015-01-07\n",
      "2015-01-08\n",
      "2015-01-09\n",
      "2015-01-10\n",
      "2015-01-11\n",
      "2015-01-12\n",
      "2015-01-13\n",
      "2015-01-14\n",
      "2015-01-15\n",
      "2015-01-16\n",
      "2015-01-17\n",
      "2015-01-18\n",
      "2015-01-19\n",
      "2015-01-20\n",
      "2015-01-21\n",
      "2015-01-22\n",
      "2015-01-23\n",
      "2015-01-24\n",
      "2015-01-25\n",
      "2015-01-26\n",
      "2015-01-27\n",
      "2015-01-28\n",
      "2015-01-29\n",
      "2015-01-30\n",
      "2015-02-08\n",
      "2015-02-09\n",
      "2015-02-10\n",
      "2015-02-11\n",
      "2015-02-12\n",
      "2015-02-13\n",
      "2015-02-14\n",
      "2015-02-15\n",
      "2015-02-16\n",
      "2015-02-17\n",
      "2015-02-18\n",
      "2015-02-19\n",
      "2015-02-20\n",
      "2015-02-21\n",
      "2015-02-22\n",
      "2015-02-23\n",
      "2015-02-24\n",
      "2015-02-25\n",
      "2015-02-26\n",
      "2015-02-27\n",
      "2015-02-28\n",
      "2015-03-01\n",
      "2015-03-02\n",
      "2015-03-03\n",
      "2015-03-04\n",
      "2015-03-05\n",
      "2015-03-06\n",
      "2015-03-07\n",
      "2015-03-08\n",
      "2015-03-09\n",
      "2015-04-22\n",
      "2015-04-23\n",
      "2015-04-24\n",
      "2015-04-25\n",
      "2015-04-26\n",
      "2015-04-27\n",
      "2015-04-28\n",
      "2015-04-29\n",
      "2015-04-30\n",
      "2015-05-01\n",
      "2015-05-02\n",
      "2015-05-03\n",
      "2015-05-04\n",
      "2015-05-05\n",
      "2015-05-06\n",
      "2015-05-07\n",
      "2015-05-08\n",
      "2015-05-09\n",
      "2015-05-10\n",
      "2015-05-11\n",
      "2015-05-12\n",
      "2015-05-13\n",
      "2015-05-14\n",
      "2015-05-15\n",
      "2015-05-16\n",
      "2015-05-17\n",
      "2015-05-18\n",
      "2015-05-19\n",
      "2015-05-20\n",
      "2015-05-21\n",
      "2015-05-22\n",
      "2015-05-23\n",
      "2015-05-24\n",
      "2015-05-25\n",
      "2015-05-26\n",
      "2015-05-27\n",
      "2015-05-28\n",
      "2015-05-29\n",
      "2015-05-30\n",
      "2015-05-31\n",
      "2015-06-01\n",
      "2015-06-02\n",
      "2015-06-03\n",
      "2015-06-04\n",
      "2015-06-05\n",
      "2015-06-06\n",
      "2015-06-07\n",
      "2015-06-08\n",
      "2015-06-09\n",
      "2015-06-10\n",
      "2015-06-11\n",
      "2015-06-12\n",
      "2015-06-13\n",
      "2015-06-14\n",
      "2015-06-15\n",
      "2015-06-16\n",
      "2015-06-17\n",
      "2015-06-18\n",
      "2015-06-19\n",
      "2015-06-20\n",
      "2015-06-21\n",
      "2015-06-22\n",
      "2015-06-23\n",
      "2015-06-24\n",
      "2015-06-25\n",
      "2015-06-26\n",
      "2015-06-27\n",
      "2015-06-28\n",
      "2015-06-29\n",
      "2015-06-30\n",
      "2015-07-01\n",
      "2015-07-02\n",
      "2015-07-03\n",
      "2015-07-04\n",
      "2015-07-05\n",
      "2015-07-06\n",
      "2015-07-07\n",
      "2015-07-08\n",
      "2015-07-09\n",
      "2015-07-10\n",
      "2015-07-11\n",
      "2015-07-12\n",
      "2015-07-13\n",
      "2015-07-14\n",
      "2015-07-15\n",
      "2015-07-16\n",
      "2015-07-17\n",
      "2015-07-18\n",
      "2015-07-19\n",
      "2015-07-20\n",
      "2015-07-21\n",
      "2015-07-22\n",
      "2015-07-23\n",
      "2015-07-24\n",
      "2015-07-25\n",
      "2015-07-26\n",
      "2015-07-27\n",
      "2015-07-28\n",
      "2015-07-29\n",
      "2015-07-30\n",
      "2015-07-31\n",
      "2015-08-01\n",
      "2015-08-02\n",
      "2015-08-03\n",
      "2015-08-04\n",
      "2015-08-05\n",
      "2015-08-06\n",
      "2015-08-07\n",
      "2015-08-08\n",
      "2015-08-09\n",
      "2015-08-10\n",
      "2015-08-11\n",
      "2015-08-12\n",
      "2015-08-13\n",
      "2015-08-14\n",
      "2015-08-15\n",
      "2015-08-16\n",
      "2015-08-17\n",
      "2015-08-18\n",
      "2015-08-19\n",
      "2015-08-20\n",
      "2015-08-21\n",
      "2015-08-22\n",
      "2015-08-23\n",
      "2015-08-24\n",
      "2015-08-25\n",
      "2015-08-26\n",
      "2015-08-27\n",
      "2015-08-28\n",
      "2015-08-29\n",
      "2015-08-30\n",
      "2015-08-31\n",
      "2015-09-01\n",
      "2015-09-02\n",
      "2015-09-03\n",
      "2015-09-04\n",
      "2015-09-05\n",
      "2015-09-06\n",
      "2015-09-07\n",
      "2015-09-08\n",
      "2015-09-09\n",
      "2015-09-10\n",
      "2015-09-11\n",
      "2015-09-12\n",
      "2015-09-13\n",
      "2015-09-14\n",
      "2015-09-15\n",
      "2015-09-16\n",
      "2015-09-17\n",
      "2015-09-18\n",
      "2015-09-19\n",
      "2015-09-20\n",
      "2015-09-21\n",
      "2015-09-22\n",
      "2015-09-23\n",
      "2015-10-23\n",
      "2015-10-24\n",
      "2015-10-25\n",
      "2015-10-26\n",
      "2015-10-27\n",
      "2015-10-28\n",
      "2015-10-29\n",
      "2015-10-30\n",
      "2015-10-31\n",
      "2015-11-01\n",
      "2015-11-02\n",
      "2015-11-03\n",
      "2015-11-04\n",
      "2015-11-05\n",
      "2015-11-06\n",
      "2015-11-07\n",
      "2015-11-08\n",
      "2015-11-09\n",
      "2015-11-10\n",
      "2015-11-11\n",
      "2015-11-12\n",
      "2015-11-13\n",
      "2015-11-14\n",
      "2015-11-15\n",
      "2015-11-16\n",
      "2015-11-17\n",
      "2015-11-18\n",
      "2015-11-19\n",
      "2015-11-20\n",
      "2015-11-21\n",
      "2015-11-22\n",
      "2015-11-23\n",
      "2015-11-24\n",
      "2015-11-25\n",
      "2015-11-26\n",
      "2015-11-27\n",
      "2015-11-28\n",
      "2015-11-29\n",
      "2015-11-30\n",
      "2015-12-01\n",
      "2015-12-02\n",
      "2015-12-03\n",
      "2015-12-04\n",
      "2015-12-05\n",
      "2015-12-06\n",
      "2015-12-07\n",
      "2015-12-08\n",
      "2015-12-09\n",
      "2015-12-10\n",
      "2015-12-11\n",
      "2015-12-12\n",
      "2015-12-13\n",
      "2015-12-14\n",
      "2015-12-15\n",
      "2015-12-16\n",
      "2015-12-17\n",
      "2015-12-18\n",
      "2015-12-19\n",
      "2015-12-20\n",
      "2015-12-21\n",
      "2015-12-22\n",
      "2015-12-23\n",
      "2015-12-24\n",
      "2015-12-25\n",
      "2015-12-26\n",
      "2015-12-27\n",
      "2015-12-28\n",
      "2015-12-29\n",
      "2015-12-30\n",
      "2015-12-31\n",
      "2016-01-01\n",
      "2016-01-02\n",
      "2016-01-03\n",
      "2016-01-04\n",
      "2016-01-05\n",
      "2016-01-06\n",
      "2016-01-07\n",
      "2016-01-08\n",
      "2016-01-09\n",
      "2016-01-10\n",
      "2016-01-11\n",
      "2016-01-12\n",
      "2016-01-13\n",
      "2016-01-14\n",
      "2016-01-15\n",
      "2016-01-16\n",
      "2016-01-17\n",
      "2016-01-18\n",
      "2016-01-19\n",
      "2016-01-20\n",
      "2016-01-21\n",
      "2016-01-22\n",
      "2016-01-23\n",
      "2016-01-24\n",
      "2016-01-25\n",
      "2016-01-26\n",
      "2016-01-27\n",
      "2016-01-28\n",
      "2016-01-29\n",
      "2016-01-30\n",
      "2016-01-31\n",
      "2016-02-01\n",
      "2016-02-02\n",
      "2016-02-03\n",
      "2016-02-04\n",
      "2016-02-05\n",
      "2016-02-06\n",
      "2016-02-07\n",
      "2016-02-08\n",
      "2016-02-09\n",
      "2016-02-10\n",
      "2016-02-11\n",
      "2016-02-12\n",
      "2016-02-13\n",
      "2016-02-14\n",
      "2016-02-15\n",
      "2016-02-16\n",
      "2016-02-17\n",
      "2016-02-18\n",
      "2016-02-20\n",
      "2016-02-21\n",
      "2016-02-22\n",
      "2016-02-23\n",
      "2016-02-24\n",
      "2016-02-25\n",
      "2016-02-26\n",
      "2016-02-27\n",
      "2016-02-28\n",
      "2016-02-29\n",
      "2016-03-01\n",
      "2016-03-02\n",
      "2016-03-03\n",
      "2016-03-04\n",
      "2016-03-05\n",
      "2016-03-06\n",
      "2016-03-07\n",
      "2016-03-08\n",
      "2016-03-09\n",
      "2016-03-10\n",
      "2016-03-11\n",
      "2016-03-12\n",
      "2016-03-13\n",
      "2016-03-14\n",
      "2016-03-15\n",
      "2016-03-16\n",
      "2016-03-17\n",
      "2016-03-18\n",
      "2016-03-19\n",
      "2016-03-20\n",
      "2016-03-21\n",
      "2016-03-22\n",
      "2016-03-23\n",
      "2016-03-24\n",
      "2016-03-25\n",
      "2016-03-26\n",
      "2016-03-27\n",
      "2016-03-28\n",
      "2016-03-29\n",
      "2016-03-30\n",
      "2016-03-31\n",
      "2016-04-01\n",
      "2016-04-02\n",
      "2016-04-03\n",
      "2016-04-04\n",
      "2016-04-05\n",
      "2016-04-06\n",
      "2016-04-07\n",
      "2016-04-08\n",
      "2016-04-09\n",
      "2016-04-10\n",
      "2016-04-11\n",
      "2016-04-12\n",
      "2016-04-13\n",
      "2016-04-14\n",
      "2016-04-15\n",
      "2016-04-16\n",
      "2016-04-17\n",
      "2016-04-18\n",
      "2016-04-19\n",
      "2016-04-20\n",
      "2016-04-21\n",
      "2016-04-22\n",
      "2016-04-23\n",
      "2016-04-24\n",
      "2016-04-25\n",
      "2016-04-26\n",
      "2016-04-27\n",
      "2016-04-28\n",
      "2016-04-29\n",
      "2016-04-30\n",
      "2016-05-01\n",
      "2016-05-02\n",
      "2016-05-03\n",
      "2016-05-04\n",
      "2016-05-05\n",
      "2016-05-06\n",
      "2016-05-07\n",
      "2016-05-08\n",
      "2016-05-09\n",
      "2016-05-10\n",
      "2016-05-11\n",
      "2016-05-12\n",
      "2016-05-13\n",
      "2016-05-14\n",
      "2016-05-15\n",
      "2016-05-16\n",
      "2016-05-17\n",
      "2016-05-18\n",
      "2016-05-19\n",
      "2016-05-20\n",
      "2016-05-21\n",
      "2016-05-22\n",
      "2016-05-23\n",
      "2016-05-24\n",
      "2016-05-25\n",
      "2016-05-26\n",
      "2016-05-27\n",
      "2016-05-28\n",
      "2016-05-29\n",
      "2016-05-30\n",
      "2016-05-31\n",
      "2016-06-01\n",
      "2016-06-02\n",
      "2016-06-03\n",
      "2016-06-04\n",
      "2016-06-05\n",
      "2016-06-06\n",
      "2016-06-07\n",
      "2016-06-08\n",
      "2016-06-09\n",
      "2016-06-10\n",
      "2016-06-11\n",
      "2016-06-12\n",
      "2016-06-13\n",
      "2016-06-14\n",
      "2016-06-15\n",
      "2016-06-16\n",
      "2016-06-17\n",
      "2016-06-18\n",
      "2016-06-19\n",
      "2016-06-20\n",
      "2016-06-21\n",
      "2016-06-22\n",
      "2016-06-23\n",
      "2016-06-24\n",
      "2016-06-25\n",
      "2016-06-26\n",
      "2016-06-27\n",
      "2016-06-28\n",
      "2016-06-29\n",
      "2016-06-30\n",
      "2016-07-01\n",
      "2016-07-02\n",
      "2016-07-03\n",
      "2016-07-04\n",
      "2016-07-05\n",
      "2016-07-06\n",
      "2016-07-07\n",
      "2016-07-08\n",
      "2016-07-09\n",
      "2016-07-10\n",
      "2016-07-11\n",
      "2016-07-12\n",
      "2016-07-13\n",
      "2016-07-14\n",
      "2016-07-15\n",
      "2016-07-16\n",
      "2016-07-17\n",
      "2016-07-18\n",
      "2016-07-19\n",
      "2016-07-20\n",
      "2016-07-21\n",
      "2016-07-22\n",
      "2016-07-23\n",
      "2016-07-24\n",
      "2016-07-25\n",
      "2016-07-26\n",
      "2016-07-27\n",
      "2016-07-28\n",
      "2016-07-29\n",
      "2016-07-30\n",
      "2016-07-31\n",
      "2016-08-01\n",
      "2016-08-02\n",
      "2016-08-03\n",
      "2016-08-04\n",
      "2016-08-05\n",
      "2016-08-06\n",
      "2016-08-07\n",
      "2016-08-08\n",
      "2016-08-09\n",
      "2016-08-10\n",
      "2016-08-11\n",
      "2016-08-12\n",
      "2016-08-13\n",
      "2016-08-14\n",
      "2016-08-15\n",
      "2016-08-16\n",
      "2016-09-06\n",
      "2016-09-07\n",
      "2016-09-08\n",
      "2016-09-09\n",
      "2016-09-10\n",
      "2016-09-11\n",
      "2016-09-12\n",
      "2016-09-13\n",
      "2016-09-14\n",
      "2016-09-15\n",
      "2016-09-16\n",
      "2016-08-17\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for day in days:\n",
    "    sub_df = df4[df4.day == day]\n",
    "    candidate = df.loc[day][1]\n",
    "    print(day)\n",
    "    if not isinstance(candidate, str):\n",
    "        l.append([day, None, None])\n",
    "        continue\n",
    "\n",
    "    pair = eval(df.loc[day][1])\n",
    "    hashtag_name = pair[0]\n",
    "    sub_df1 = sub_df['hashtags'].apply(lambda x: hashtag_name in x)\n",
    "    a = sub_df[sub_df1]['placeId'].value_counts()\n",
    "    \n",
    "    l.append([day, a.index[0], a[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"web/Analysis/overall_topics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['place'] = df['1'].apply(lambda x: '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['has_event'] = df['1'].apply(lambda x: True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4['hashtags'] = df4['hashtags'].apply(lambda x: [i.lower() for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>place</th>\n",
       "      <th>has_event</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-28</th>\n",
       "      <td>('davidebraccialetti', 123261065.61367945)</td>\n",
       "      <td>('braccialettirossi', 1090408.4759098201)</td>\n",
       "      <td>('switzerlandneedsotrat', 3840.3278728453806)</td>\n",
       "      <td>('atamadafelsefeyiunutma', 1332.25)</td>\n",
       "      <td>('switzerland', 14.310981274630031)</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29</th>\n",
       "      <td>('switzerlandneedsotratour', 33731885.168040439)</td>\n",
       "      <td>('wewantotrainitaly2015', 59691.948014615453)</td>\n",
       "      <td>('yeniturkiyei̇nsasindafelsefe', 5852.25)</td>\n",
       "      <td>('switzerlandneedsotrat', 1447.4907518659709)</td>\n",
       "      <td>('nashschristmasskit', 1447.300469211865)</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30</th>\n",
       "      <td>('switzerlandneeds1dotrat', 4787810.3267061366)</td>\n",
       "      <td>('20thingsiwantfor2015', 1301800.3725766602)</td>\n",
       "      <td>('switzerlandneedsotratour', 469414.36452214647)</td>\n",
       "      <td>('neolieberswag', 17131.67488468088)</td>\n",
       "      <td>('hollywoodmusicawards', 12773.295797828736)</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>('weneedotrainitaly2015', 825372.25)</td>\n",
       "      <td>('openrafahborder', 805625.18410325912)</td>\n",
       "      <td>('2015', 103923.94751935355)</td>\n",
       "      <td>('happynewyear', 35881.731805671974)</td>\n",
       "      <td>('20thingsiwantfor2015', 29640.744207429976)</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>('ilovesuperjunior', 924482.25)</td>\n",
       "      <td>('ilovebts', 170625.6504743275)</td>\n",
       "      <td>('dmmedagi', 117581.10652550224)</td>\n",
       "      <td>('2015', 77109.746378452517)</td>\n",
       "      <td>('happynewyear', 14038.574809500005)</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           1  \\\n",
       "date                                                           \n",
       "2014-12-28        ('davidebraccialetti', 123261065.61367945)   \n",
       "2014-12-29  ('switzerlandneedsotratour', 33731885.168040439)   \n",
       "2014-12-30   ('switzerlandneeds1dotrat', 4787810.3267061366)   \n",
       "2014-12-31              ('weneedotrainitaly2015', 825372.25)   \n",
       "2015-01-01                   ('ilovesuperjunior', 924482.25)   \n",
       "\n",
       "                                                        2  \\\n",
       "date                                                        \n",
       "2014-12-28      ('braccialettirossi', 1090408.4759098201)   \n",
       "2014-12-29  ('wewantotrainitaly2015', 59691.948014615453)   \n",
       "2014-12-30   ('20thingsiwantfor2015', 1301800.3725766602)   \n",
       "2014-12-31        ('openrafahborder', 805625.18410325912)   \n",
       "2015-01-01                ('ilovebts', 170625.6504743275)   \n",
       "\n",
       "                                                           3  \\\n",
       "date                                                           \n",
       "2014-12-28     ('switzerlandneedsotrat', 3840.3278728453806)   \n",
       "2014-12-29         ('yeniturkiyei̇nsasindafelsefe', 5852.25)   \n",
       "2014-12-30  ('switzerlandneedsotratour', 469414.36452214647)   \n",
       "2014-12-31                      ('2015', 103923.94751935355)   \n",
       "2015-01-01                  ('dmmedagi', 117581.10652550224)   \n",
       "\n",
       "                                                        4  \\\n",
       "date                                                        \n",
       "2014-12-28            ('atamadafelsefeyiunutma', 1332.25)   \n",
       "2014-12-29  ('switzerlandneedsotrat', 1447.4907518659709)   \n",
       "2014-12-30           ('neolieberswag', 17131.67488468088)   \n",
       "2014-12-31           ('happynewyear', 35881.731805671974)   \n",
       "2015-01-01                   ('2015', 77109.746378452517)   \n",
       "\n",
       "                                                       5 place has_event  \n",
       "date                                                                      \n",
       "2014-12-28           ('switzerland', 14.310981274630031)            True  \n",
       "2014-12-29     ('nashschristmasskit', 1447.300469211865)            True  \n",
       "2014-12-30  ('hollywoodmusicawards', 12773.295797828736)            True  \n",
       "2014-12-31  ('20thingsiwantfor2015', 29640.744207429976)            True  \n",
       "2015-01-01          ('happynewyear', 14038.574809500005)            True  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_geo_infomation = pd.DataFrame(l, columns=['date', 'placeId', 'place_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"data/twitter-swisscom/geo/geo_info_total.pickle\", \"rb\") as h:\n",
    "    geo = pickle.load(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>1</th>\n",
       "      <th>placeId</th>\n",
       "      <th>placeLatitude</th>\n",
       "      <th>placeLongitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000831c517105356</td>\n",
       "      <td>16.9866</td>\n",
       "      <td>103.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a93ad12003aaa</td>\n",
       "      <td>46.8911</td>\n",
       "      <td>7.51217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000b5d1aada9dcaa</td>\n",
       "      <td>46.9525</td>\n",
       "      <td>7.4459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0010c7694b04e371</td>\n",
       "      <td>47.4261</td>\n",
       "      <td>8.50569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0013241b7342de79</td>\n",
       "      <td>47.0462</td>\n",
       "      <td>8.30735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "1           placeId placeLatitude placeLongitude\n",
       "0  000831c517105356       16.9866         103.94\n",
       "1  000a93ad12003aaa       46.8911        7.51217\n",
       "2  000b5d1aada9dcaa       46.9525         7.4459\n",
       "3  0010c7694b04e371       47.4261        8.50569\n",
       "4  0013241b7342de79       47.0462        8.30735"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trend = pd.merge(df.reset_index(), topic_geo_infomation, on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.merge(trend, geo, on='placeId', how='left').set_index('date')\n",
    "d['has_event'] = d['1'].apply(lambda x: type(x) == str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export = d[['1', 'has_event', 'place_value', 'placeLatitude', 'placeLongitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export1 = export[export.has_event].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>has_event</th>\n",
       "      <th>place_value</th>\n",
       "      <th>placeLatitude</th>\n",
       "      <th>placeLongitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-28</th>\n",
       "      <td>('davidebraccialetti', 123261065.61367945)</td>\n",
       "      <td>True</td>\n",
       "      <td>192.0</td>\n",
       "      <td>46.3293</td>\n",
       "      <td>9.4055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29</th>\n",
       "      <td>('switzerlandneedsotratour', 33731885.168040439)</td>\n",
       "      <td>True</td>\n",
       "      <td>22.0</td>\n",
       "      <td>46.2504</td>\n",
       "      <td>8.27646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30</th>\n",
       "      <td>('switzerlandneeds1dotrat', 4787810.3267061366)</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46.2219</td>\n",
       "      <td>6.18194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>('weneedotrainitaly2015', 825372.25)</td>\n",
       "      <td>True</td>\n",
       "      <td>34.0</td>\n",
       "      <td>47.3774</td>\n",
       "      <td>8.53676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>('ilovesuperjunior', 924482.25)</td>\n",
       "      <td>True</td>\n",
       "      <td>70.0</td>\n",
       "      <td>47.7218</td>\n",
       "      <td>7.28274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           1 has_event  \\\n",
       "date                                                                     \n",
       "2014-12-28        ('davidebraccialetti', 123261065.61367945)      True   \n",
       "2014-12-29  ('switzerlandneedsotratour', 33731885.168040439)      True   \n",
       "2014-12-30   ('switzerlandneeds1dotrat', 4787810.3267061366)      True   \n",
       "2014-12-31              ('weneedotrainitaly2015', 825372.25)      True   \n",
       "2015-01-01                   ('ilovesuperjunior', 924482.25)      True   \n",
       "\n",
       "            place_value placeLatitude placeLongitude  \n",
       "date                                                  \n",
       "2014-12-28        192.0       46.3293         9.4055  \n",
       "2014-12-29         22.0       46.2504        8.27646  \n",
       "2014-12-30         10.0       46.2219        6.18194  \n",
       "2014-12-31         34.0       47.3774        8.53676  \n",
       "2015-01-01         70.0       47.7218        7.28274  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export1['topic'] = export1['1'].apply(lambda x: eval(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export1['chi_squared'] = export1['1'].apply(lambda x: eval(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export1[['place_value', 'placeLatitude', 'placeLongitude', 'topic', 'chi_squared']].to_csv(\"event_detection.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Trend in different place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First create a dictionary of placeId to their all their hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base1 = df1[['placeId', 'hashtags']].groupby('placeId').aggregate(lambda x: [i for l in x for i in l ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base2 = df2[['placeId', 'hashtags']].groupby('placeId').aggregate(lambda x: [i for l in x for i in l ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base3 = df3[['placeId', 'hashtags']].groupby('placeId').aggregate(lambda x: [i for l in x for i in l ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twtter_count1 = df1.groupby('placeId').count()[['id']]\n",
    "twtter_count2 = df2.groupby('placeId').count()[['id']]\n",
    "twtter_count3 = df3.groupby('placeId').count()[['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twtter_count1.columns = ['base_twitter_count']\n",
    "twtter_count2.columns = ['base_twitter_count']\n",
    "twtter_count3.columns = ['base_twitter_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitter_count = pd.concat([twtter_count1, twtter_count2, twtter_count3], axis=1).fillna(0).apply(lambda x: np.sum(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_count = pd.DataFrame(twitter_count, columns=['base_twitter_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge three part of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = pd.concat([base1, base2, base3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000831c517105356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000a93ad12003aaa</th>\n",
       "      <td>[Zurich, drs3, wikipedia, gdi, fb, Basel, FCB,...</td>\n",
       "      <td>[Kreis11, Zürich, myclimate, Abflug, Amsterdam...</td>\n",
       "      <td>[GenevaMotorShow, PoloStMoritz2014, polo, resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000b5d1aada9dcaa</th>\n",
       "      <td>[jäten, creativemornings, SCB, HCFG, telezüri,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010c7694b04e371</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0013241b7342de79</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           hashtags  \\\n",
       "000831c517105356                                                NaN   \n",
       "000a93ad12003aaa  [Zurich, drs3, wikipedia, gdi, fb, Basel, FCB,...   \n",
       "000b5d1aada9dcaa  [jäten, creativemornings, SCB, HCFG, telezüri,...   \n",
       "0010c7694b04e371                                                 []   \n",
       "0013241b7342de79                                                 []   \n",
       "\n",
       "                                                           hashtags  \\\n",
       "000831c517105356                                                NaN   \n",
       "000a93ad12003aaa  [Kreis11, Zürich, myclimate, Abflug, Amsterdam...   \n",
       "000b5d1aada9dcaa                                                NaN   \n",
       "0010c7694b04e371                                                NaN   \n",
       "0013241b7342de79                                                 []   \n",
       "\n",
       "                                                           hashtags  \n",
       "000831c517105356                                                 []  \n",
       "000a93ad12003aaa  [GenevaMotorShow, PoloStMoritz2014, polo, resi...  \n",
       "000b5d1aada9dcaa                                                NaN  \n",
       "0010c7694b04e371                                                NaN  \n",
       "0013241b7342de79                                                NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = c.applymap(lambda x: x if isinstance(x, list) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_dict_by_place = pd.DataFrame(c.apply(lambda x: [i for l in x for i in l], axis=1), columns=['hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000831c517105356</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000a93ad12003aaa</th>\n",
       "      <td>[Zurich, drs3, wikipedia, gdi, fb, Basel, FCB,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000b5d1aada9dcaa</th>\n",
       "      <td>[jäten, creativemornings, SCB, HCFG, telezüri,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010c7694b04e371</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0013241b7342de79</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           hashtags\n",
       "000831c517105356                                                 []\n",
       "000a93ad12003aaa  [Zurich, drs3, wikipedia, gdi, fb, Basel, FCB,...\n",
       "000b5d1aada9dcaa  [jäten, creativemornings, SCB, HCFG, telezüri,...\n",
       "0010c7694b04e371                                                 []\n",
       "0013241b7342de79                                                 []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dict_by_place.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dict_by_place['dict'] = base_dict_by_place['hashtags'].apply(lambda x: count_hash_tags(pd.Series([x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_dict_by_place['count'] = base_dict_by_place['hashtags'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_dict_by_place = pd.concat([twitter_count, base_dict_by_place], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_twitter_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>dict</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000831c517105356</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000a93ad12003aaa</th>\n",
       "      <td>2580.0</td>\n",
       "      <td>[Zurich, drs3, wikipedia, gdi, fb, Basel, FCB,...</td>\n",
       "      <td>{'g07f': 1, 'windowsphone81': 1, 'g07f7': 1, '...</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000b5d1aada9dcaa</th>\n",
       "      <td>46.0</td>\n",
       "      <td>[jäten, creativemornings, SCB, HCFG, telezüri,...</td>\n",
       "      <td>{'itunes': 1, 'flgi': 1, 'talktäglich': 1, 'ta...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010c7694b04e371</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0013241b7342de79</th>\n",
       "      <td>7.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  base_twitter_count  \\\n",
       "000831c517105356                 1.0   \n",
       "000a93ad12003aaa              2580.0   \n",
       "000b5d1aada9dcaa                46.0   \n",
       "0010c7694b04e371                 2.0   \n",
       "0013241b7342de79                 7.0   \n",
       "\n",
       "                                                           hashtags  \\\n",
       "000831c517105356                                                 []   \n",
       "000a93ad12003aaa  [Zurich, drs3, wikipedia, gdi, fb, Basel, FCB,...   \n",
       "000b5d1aada9dcaa  [jäten, creativemornings, SCB, HCFG, telezüri,...   \n",
       "0010c7694b04e371                                                 []   \n",
       "0013241b7342de79                                                 []   \n",
       "\n",
       "                                                               dict  count  \n",
       "000831c517105356                                                 {}      0  \n",
       "000a93ad12003aaa  {'g07f': 1, 'windowsphone81': 1, 'g07f7': 1, '...    779  \n",
       "000b5d1aada9dcaa  {'itunes': 1, 'flgi': 1, 'talktäglich': 1, 'ta...     32  \n",
       "0010c7694b04e371                                                 {}      0  \n",
       "0013241b7342de79                                                 {}      0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dict_by_place.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
